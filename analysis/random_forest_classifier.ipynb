{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA and data handling\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modeling\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>release_date</th>\n",
       "      <th>year</th>\n",
       "      <th>top_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Psycho</td>\n",
       "      <td>When larcenous real estate clerk Marion Crane ...</td>\n",
       "      <td>1960-06-22</td>\n",
       "      <td>1960</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sleep Has Her House</td>\n",
       "      <td>The shadows of screams climb beyond the hills....</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antrum</td>\n",
       "      <td>Rumored to have been lost, Antrum appears as a...</td>\n",
       "      <td>2018-10-14</td>\n",
       "      <td>2018</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>Clarice Starling is a top student at the FBI's...</td>\n",
       "      <td>1991-02-01</td>\n",
       "      <td>1991</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>House of the Disappeared</td>\n",
       "      <td>After 25 years of imprisonment for familicide,...</td>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>2017</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title  \\\n",
       "0                    Psycho   \n",
       "1       Sleep Has Her House   \n",
       "2                    Antrum   \n",
       "3  The Silence of the Lambs   \n",
       "4  House of the Disappeared   \n",
       "\n",
       "                                            overview release_date  year  \\\n",
       "0  When larcenous real estate clerk Marion Crane ...   1960-06-22  1960   \n",
       "1  The shadows of screams climb beyond the hills....   2017-01-01  2017   \n",
       "2  Rumored to have been lost, Antrum appears as a...   2018-10-14  2018   \n",
       "3  Clarice Starling is a top student at the FBI's...   1991-02-01  1991   \n",
       "4  After 25 years of imprisonment for familicide,...   2017-04-05  2017   \n",
       "\n",
       "  top_genre  \n",
       "0    Horror  \n",
       "1    Horror  \n",
       "2    Horror  \n",
       "3    Horror  \n",
       "4    Horror  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horror_flicks=pd.read_csv('../data/horror_flicks.csv')\n",
    "horror_flicks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3410, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('../data/tmdb_movie_plots.csv')\n",
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "movies=pd.concat([movies, horror_flicks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>...</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>top_genre</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000.0</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995.0</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>...</td>\n",
       "      <td>2.787965e+09</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>Action</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800.0</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300000000.0</td>\n",
       "      <td>[{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...</td>\n",
       "      <td>http://disney.go.com/disneypictures/pirates/</td>\n",
       "      <td>285.0</td>\n",
       "      <td>[{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...</td>\n",
       "      <td>en</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa, long believed to be dead, ha...</td>\n",
       "      <td>139.082615</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>9.610000e+08</td>\n",
       "      <td>169.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>At the end of the world, the adventure begins.</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Adventure</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        budget                                             genres  \\\n",
       "0  237000000.0  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "1  300000000.0  [{\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"...   \n",
       "\n",
       "                                       homepage       id  \\\n",
       "0                   http://www.avatarmovie.com/  19995.0   \n",
       "1  http://disney.go.com/disneypictures/pirates/    285.0   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
       "1  [{\"id\": 270, \"name\": \"ocean\"}, {\"id\": 726, \"na...                en   \n",
       "\n",
       "                             original_title  \\\n",
       "0                                    Avatar   \n",
       "1  Pirates of the Caribbean: At World's End   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "1  Captain Barbossa, long believed to be dead, ha...  139.082615   \n",
       "\n",
       "                                production_companies  ...       revenue  \\\n",
       "0  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...  ...  2.787965e+09   \n",
       "1  [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...  ...  9.610000e+08   \n",
       "\n",
       "  runtime                                   spoken_languages    status  \\\n",
       "0   162.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...  Released   \n",
       "1   169.0           [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
       "\n",
       "                                          tagline  \\\n",
       "0                     Enter the World of Pandora.   \n",
       "1  At the end of the world, the adventure begins.   \n",
       "\n",
       "                                      title  top_genre vote_average  \\\n",
       "0                                    Avatar     Action          7.2   \n",
       "1  Pirates of the Caribbean: At World's End  Adventure          6.9   \n",
       "\n",
       "  vote_count  year  \n",
       "0    11800.0  2009  \n",
       "1     4500.0  2007  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies[['title', 'overview', 'year', 'top_genre']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title        0\n",
       "overview     5\n",
       "year         0\n",
       "top_genre    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " movies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3890, 4)\n",
      "(3885, 4)\n"
     ]
    }
   ],
   "source": [
    "# remove unlabeled data\n",
    "print(movies.shape)\n",
    "movies=movies.dropna(how='any')\n",
    "print(movies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'overview', 'year', 'top_genre'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns\n",
    "movies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(\n",
    "#                        input='content', \n",
    "#                        encoding='utf-8', \n",
    "#                        decode_error='strict', \n",
    "                       strip_accents='unicode', \n",
    "                       lowercase=True, \n",
    "#                        preprocessor=None, \n",
    "                       tokenizer='word_tokenize', \n",
    "#                        analyzer='word', \n",
    "                       stop_words='english', \n",
    "#                        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', \n",
    "#                        ngram_range=(1,3), \n",
    "#                        max_df=1.0, \n",
    "#                        min_df=1, \n",
    "#                        max_features=None, \n",
    "#                        vocabulary=True, \n",
    "#                        binary=False, \n",
    "#                        dtype=<class 'numpy.int64'>, \n",
    "#                        norm='l2', \n",
    "#                        use_idf=True, \n",
    "#                        smooth_idf=True, \n",
    "#                        sublinear_tf=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-43ad88383b2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'overview'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1650\u001b[0m         \"\"\"\n\u001b[1;32m   1651\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1058\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    968\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    350\u001b[0m                                                tokenize)\n\u001b[1;32m    351\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 352\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "test = tvec.fit_transform(movies['overview'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>07am</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>108</th>\n",
       "      <th>10th</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zooey</th>\n",
       "      <th>zookeeper</th>\n",
       "      <th>zoolander</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoozie</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>Ã¦on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.332854</td>\n",
       "      <td>4.901328</td>\n",
       "      <td>0.373429</td>\n",
       "      <td>0.192179</td>\n",
       "      <td>4.886624</td>\n",
       "      <td>0.978866</td>\n",
       "      <td>0.390658</td>\n",
       "      <td>0.197029</td>\n",
       "      <td>0.523067</td>\n",
       "      <td>3.902484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257865</td>\n",
       "      <td>1.915002</td>\n",
       "      <td>0.759334</td>\n",
       "      <td>0.6521</td>\n",
       "      <td>0.184571</td>\n",
       "      <td>0.214436</td>\n",
       "      <td>0.122702</td>\n",
       "      <td>0.172667</td>\n",
       "      <td>0.339262</td>\n",
       "      <td>0.247021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 18444 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00       000       007      07am        10       100      1000  \\\n",
       "0  0.332854  4.901328  0.373429  0.192179  4.886624  0.978866  0.390658   \n",
       "\n",
       "        108      10th        11  ...     zones       zoo     zooey  zookeeper  \\\n",
       "0  0.197029  0.523067  3.902484  ...  0.257865  1.915002  0.759334     0.6521   \n",
       "\n",
       "   zoolander      zoom    zoozie     zorro  zuckerberg       Ã¦on  \n",
       "0   0.184571  0.214436  0.122702  0.172667    0.339262  0.247021  \n",
       "\n",
       "[1 rows x 18444 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(test.sum(axis=0),\n",
    "                       columns=tvec.get_feature_names())\n",
    "word_counts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3885, 18444)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3885, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the genres\n",
    "movies['top_genre'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the target variable\n",
    "choice='Horror'\n",
    "movies['target']=0\n",
    "movies.loc[movies['top_genre']==choice, 'target']=1\n",
    "movies['target'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine a few\n",
    "movies[movies['target']==1].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) \n",
    "msk = np.random.rand(len(movies)) < 0.8\n",
    "train = movies[msk]\n",
    "test = movies[~msk]\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many in the test class?\n",
    "print(test['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many in the train class?\n",
    "print(train['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample the majority class\n",
    "undersample = train[train['target']==0].sample(600, random_state=42)\n",
    "train_aug=train[train['target']==1].append(undersample)\n",
    "train_aug['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X and y\n",
    "X_train=train_aug['overview']\n",
    "X_test=test['overview']\n",
    "y_train=train_aug['target']\n",
    "y_test=test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the difference in train and test. Don't fit on the test data! (d'oh)\n",
    "tvec.fit(X_train)\n",
    "Xvec_train = tvec.transform(X_train)\n",
    "Xvec_test  = tvec.transform(X_test)\n",
    "# We pickle tvec later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common words\n",
    "word_counts = pd.DataFrame(Xvec_train.sum(axis=0),\n",
    "                       columns=tvec.get_feature_names())\n",
    "word_counts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Most common: \\n \\n', word_counts.T.sort_values(by=0,ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xvec_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grid search parameters\n",
    "# param_grid = {\n",
    "# #         'n_estimators': [100, 'warn'], \n",
    "# #         'max_depth': [3, 4, 5, None],\n",
    "# #         'min_samples_split': [2, 3, 4, 5],\n",
    "# #         'min_samples_leaf': [1, 2, 3, 4, 5],         \n",
    "# #         'max_features': [5, 10, 15, 'auto'], \n",
    "# #         'class_weight': [None],\n",
    "# #         'criterion':['entropy', 'gini'],\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # conduct gridsearch\n",
    "# grid = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, n_jobs = 1, cv=3, verbose=False)\n",
    "# grid.fit(Xvec_train, y_train)\n",
    "# print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate model using those parameters\n",
    "# my_model = grid.best_estimator_\n",
    "# print(my_model)\n",
    "# Model parameters\n",
    "# print(my_model.get_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model=RandomForestClassifier()\n",
    "my_model.fit(Xvec_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the RF model\n",
    "file = open(f'trained_rf_model.pkl', 'wb')\n",
    "pickle.dump(my_model, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test data\n",
    "y_preds=my_model.predict(Xvec_test)\n",
    "print(len(y_test))\n",
    "len(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilities\n",
    "y_probs = my_model.predict_proba(Xvec_test)[:,1]\n",
    "len(y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy score\n",
    "metrics.accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision and recall \n",
    "print(metrics.classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_preds)\n",
    "pd.DataFrame(cm, columns=['pred_0', 'pred_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_preds).ravel()\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROCAUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPR = dict()\n",
    "TPR = dict()\n",
    "ROC_AUC = dict()\n",
    "# For class 1 (has WNV), find the area under the curve:\n",
    "FPR[1], TPR[1], _ = roc_curve(y_test, y_probs)\n",
    "ROC_AUC[1] = auc(FPR[1], TPR[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is that ROC-AUC score?\n",
    "print(ROC_AUC[1])\n",
    "# Same but using the scikit default:\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's draw that:\n",
    "plt.style.use('seaborn-white')\n",
    "plt.figure(figsize=[11,9])\n",
    "plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=18)\n",
    "plt.ylabel('True Positive Rate', fontsize=18)\n",
    "plt.title('ROC Curve', fontsize=18)\n",
    "plt.legend(loc=\"lower right\", fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x  = pd.DataFrame(Xvec_test.todense(),\n",
    "             columns=tvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({\n",
    "        'feature':df_x.columns,\n",
    "        'importance':my_model.feature_importances_\n",
    "    })\n",
    "\n",
    "fi.sort_values('importance', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features most associated with target\n",
    "top20=pd.DataFrame(fi.sort_values('importance', ascending=False).head(20))\n",
    "print(top20['feature'].values)\n",
    "top20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set(style=\"darkgrid\", color_codes=None)\n",
    "# sns.palplot(sns.color_palette(\"RdBu\", n_colors=7))\n",
    "ax = top20.set_index('feature').plot(kind='bar', legend=False, fontsize=18,  figsize=(15, 7))\n",
    "plt.xticks(rotation = 45,  fontsize=18)\n",
    "plt.title('Most Important Predictors',  fontsize=19)\n",
    "plt.yticks(rotation = 0,  fontsize=18)\n",
    "plt.ylabel('Feature Importance', rotation=90,  fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save that dataframe\n",
    "top20.to_csv('top20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's display that with Plotly.\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "# import plotly.io as pio\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "# Define the color palette (19 colors).\n",
    "Viridis= ['#440154', '#48186a', '#472d7b', '#424086', '#3b528b', '#33638d', '#2c728e', '#26828e', '#21918c', '#1fa088',\n",
    "          '#28ae80', '#3fbc73', '#5ec962', '#84d44b', '#84d44b', '#addc30','#d8e219', '#fde725',  '#fde725']   \n",
    "\n",
    "mydata = [go.Bar(\n",
    "    x=top20['feature'],\n",
    "    y=top20['importance'],\n",
    "    marker=dict(color=Viridis[::-1])\n",
    ")]\n",
    "\n",
    "mylayout = go.Layout(\n",
    "    title='What makes it a horror film?',\n",
    "    xaxis = dict(title = 'Feature Importance'), \n",
    "    yaxis = dict(title = 'Top Words'), \n",
    "\n",
    ")\n",
    "fig = go.Figure(data=mydata, layout=mylayout)\n",
    "# pio.write_image(fig, '../images/logistic.png')\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A confusion matrix tells us our false positives and false negatives:\n",
    "matrix=metrics.confusion_matrix(y_test, y_preds)\n",
    "cm=pd.DataFrame(matrix, columns=['predicted: no', 'predicted: yes'], index=['ground truth: no', 'ground truth: yes'])\n",
    "cm=cm.reset_index(drop=False)\n",
    "cm=cm.rename(columns={'index': f'n = {len(y_test)}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "table = ff.create_table(cm)\n",
    "iplot(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.to_csv('conf_matrix.csv', index=False)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdata = train[train['target']==1]['overview'].sample(1).values\n",
    "newdata = ['this is a test this is just a test funny funny joke ha']\n",
    "tvec_test=tvec.transform(newdata)\n",
    "preds_test=my_model.predict(tvec_test)\n",
    "preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the vectorizer\n",
    "file = open('vectorizer.pkl', 'wb')\n",
    "pickle.dump(tvec, file)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
